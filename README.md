# DSCI510_Final_Project

This project was completed for DSCI 510: Principles of Programming for Data Science.
The goal is to scrape online book data, clean it, analyze price–rating patterns, and visualize the results.

**Team Members**
Name: Shirley(Xue) Feng
Email: shirleyf@usc.edu
GitHub Username: snowxxxue
USC ID: 7145-1490-57

**Project Overview**
This project collects book information from the website **Books to Scrape**, processes the raw HTML data, performs basic descriptive analysis, and generates visualizations to explore how book prices and ratings behave on the platform.

The full workflow includes:
1. **Web Scraping** (requests + BeautifulSoup)
2. **Data Cleaning** (convert price, map rating text to numbers, remove symbols)
3. **Data Analysis** (descriptive statistics, exploratory insights)
4. **Data Visualization** (histograms, scatter plots, bar charts)


**Directory Structure**
```
├── README.md
├── requirements.txt
├── project_proposal.pdf
├── data/
│   ├── raw/          # Raw scraped data (HTML/CSV/JSON)
│   └── processed/    # Cleaned CSV dataset
├── results/
│   ├── final_report.pdf
│   └── figures/      # All plots generated by visualize_results.py
└── src/
    ├── get_data.py
    ├── clean_data.py
    ├── run_analysis.py
    ├── visualize_results.py
    └── utils/
```

**Installation Instructions**
Before running the project, install all required Python libraries.

**1. Clone the repository**

```
git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>
```

**2. Install dependencies**

```
pip install -r requirements.txt
```

## **How to Run the Project**
The project follows a sequential workflow. Please run each script in order.
**Step 1 — Get Data**
Scrape book titles, prices, ratings, and URLs from *Books to Scrape*.

```
python src/get_data.py
```

**Output:**

* Raw scraped files saved under `data/raw/`.

**Step 2 — Clean Data**
Convert price strings to numeric values, map rating text (e.g., “Three”) to numbers, remove symbols, and save a structured CSV.

```
python src/clean_data.py
```

**Output:**

* `data/processed/books_clean.csv`


**Step 3 — Run Analysis**
Perform descriptive statistics such as average price, min/max, price distribution, and basic correlations.

```
python src/run_analysis.py
```

**Output:**

* Summary statistics printed in terminal or saved in `results/`.


**Step 4 — Produce Visualizations**
Generate all figures, including:

* Price distribution histogram
* Rating distribution bar chart
* Price vs. rating scatter plot
* Top 10 highest-priced books plot

```
python src/visualize_results.py
```

**Output:**

* All images saved under `results/figures/`



**Data Sources**

The project uses the public demo site:

**[http://books.toscrape.com/](http://books.toscrape.com/)**
This website is specifically created for practicing web scraping and does not block automated requests.


**Final Report**

The final project report is located in:

`results/final_report.pdf`

It includes:

* Project motivation
* Data collection details
* Cleaning methods
* Visualizations with explanations
* Observations & conclusions
* Future work




